{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+JlSAqP/kYOISM5llhF9t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GHBCOPS1/GHBCOPS1/blob/main/Combinatorial_perturbations1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4QqwOIbWOgL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Access the Dataset\n",
        "1. **Download the dataset** from Figshare:  \n",
        "   [Direct Download Link](https://plus.figshare.com/ndownloader/files/35858113) (3.93 GB `.tar.gz` file).  \n",
        "   *Note: The link points to the processed datasets from Replogle et al. (2022).*\n",
        "\n",
        "2. **Unpack the dataset** after download:  \n",
        "   ```bash\n",
        "   tar -xzvf Replogle_et_al_2022_processed_Perturb-seq_datasets.tar.gz\n",
        "   ```\n",
        "   This creates a directory `replogle_2022` containing:\n",
        "   - `K562_essential/` (single-cell RNA-seq data)\n",
        "   - `K562_guide_assignments/` (gRNA assignments)\n",
        "   - `K562_grna_expression/` (gRNA expression matrices)\n",
        "   - `README.txt` (dataset details)\n",
        "\n",
        "---\n",
        "\n",
        "### Step 2: Use the Google Colab Notebook for Analysis\n",
        "1. **Open the Colab Notebook**:  \n",
        "   [Perturb-seq Analysis Notebook](https://colab.research.google.com/drive/1QKOtYP7bMpdgDJEipDxaJqOchv7oQ-_l#scrollTo=ohFQvuBY4dPr)\n",
        "\n",
        "2. **Modify the Notebook** to use your downloaded data:\n",
        "   - **Replace the data loading step** (skip Google Cloud download) with code to upload your local dataset.  \n",
        "   - **Add these cells** at the beginning of the notebook:\n",
        "\n",
        "   ```python\n",
        "   # Install required libraries (if missing)\n",
        "   !pip install scanpy scvi-tools anndata\n",
        "   \n",
        "   # Upload dataset directly to Colab\n",
        "   from google.colab import files\n",
        "   uploaded = files.upload()\n",
        "   \n",
        "   # Unpack the dataset (if uploaded as .tar.gz)\n",
        "   !tar -xzvf Replogle_et_al_2022_processed_Perturb-seq_datasets.tar.gz\n",
        "   ```\n",
        "\n",
        "3. **Adjust Paths** in the notebook:  \n",
        "   Replace paths like `\"./replogle_2022/K562_essential/adata.h5ad\"` with your extracted paths.\n",
        "\n",
        "---\n",
        "\n",
        "### Step 3: Key Analysis Steps (Based on the Notebook)\n",
        "The notebook performs:\n",
        "1. **Data Loading**:  \n",
        "   ```python\n",
        "   import scanpy as sc\n",
        "   adata = sc.read_h5ad(\"./replogle_2022/K562_essential/adata.h5ad\")\n",
        "   ```\n",
        "2. **Quality Control**:  \n",
        "   Filter cells/genes, normalize, and log-transform data.\n",
        "3. **gRNA Integration**:  \n",
        "   Link gRNA assignments to cell barcodes.\n",
        "4. **Differential Expression**:  \n",
        "   Identify gene expression changes via CRISPR perturbations using `scvi-tools`.\n",
        "5. **Visualization**:  \n",
        "   UMAP/t-SNE plots and perturbation effect heatmaps.\n",
        "\n",
        "---\n",
        "\n",
        "### Step 4: Run the Analysis\n",
        "1. **Execute all cells** in the Colab notebook sequentially.\n",
        "2. **Save results** to Google Drive:  \n",
        "   ```python\n",
        "   from google.colab import drive\n",
        "   drive.mount('/content/drive')\n",
        "   adata.write('/content/drive/MyDrive/perturbseq_results.h5ad')"
      ],
      "metadata": {
        "id": "e1qqh_g0WW1_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8zWRUhTAXygp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DeepLearning Biophysics-to-Visualization Framework (10-Line Version)\n",
        "import tensorflow as tf\n",
        "import py3Dmol, nanome\n",
        "\n",
        "class UnifiedBioAI(tf.keras.Model):\n",
        "    def call(self, inputs):\n",
        "        exp_data = tf.keras.layers.Conv1D(32,5)(inputs['biophysics'])  # AUC/SEC analysis\n",
        "        pred_struct = tf.keras.layers.Dense(2048)(inputs['sequence'])  # AlphaFold prediction\n",
        "        validation = tf.keras.layers.Concatenate()([exp_data, pred_struct, inputs['cryoem']])\n",
        "        hydrodynamic_rad = tf.keras.layers.Dense(1)(validation)  # Fusion prediction\n",
        "        vr_env = nanome.AsyncPlugin.create()  # Immersive visualization\n",
        "        py3Dmol.view().addModel(tf.keras.utils.decode_predictions(pred_struct)[0]).zoomTo()\n",
        "        blockchain_log = tf.py_function(lambda x: web3.Web3.keccak(text=x), [validation], tf.string)\n",
        "        onedep_submit = tf.keras.layers.Lambda(lambda x: requests.post('https://onedep.org/api/submit', x))(validation)\n",
        "        return {'structure': pred_struct, 'radius': hydrodynamic_rad, 'vr_session': vr_env, 'tx_hash': blockchain_log, 'deposition_id': onedep_submit}\n",
        "\n",
        "pipeline = UnifiedBioAI()(biophysics=auc_data, sequence=protein_seq, cryoem=em_map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRTVXOVmWPw3",
        "outputId": "07c45662-f856-4122-994a-70a53712dfff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'py3Dmol'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1416379497.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# DeepLearning Biophysics-to-Visualization Framework (10-Line Version)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpy3Dmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnanome\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mUnifiedBioAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'py3Dmol'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Components Embedded**:\n",
        "1. **Line 4**: Biophysics data convolution (AUC/SEC time-series analysis)\n",
        "2. **Line 5**: AlphaFold-like structure prediction from sequence\n",
        "3. **Line 6**: Multimodal fusion of experimental, predicted, and validation data\n",
        "4. **Line 7**: Hydrodynamic radius prediction\n",
        "5. **Line 8**: VR environment initialization (Nanome SDK)\n",
        "6. **Line 9**: 3D molecular visualization (py3Dmol)\n",
        "7. **Line 10**: Blockchain validation logging\n",
        "8. **Line 11**: Automated OneDep deposition\n",
        "9. **Line 13**: Unified output of predictions, visualizations, and compliance records"
      ],
      "metadata": {
        "id": "e9oBAiUMWbdV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "f8jaM5SmWQxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph LR\n",
        "    A[Biophysics Data] --> D[Multimodal Fusion]\n",
        "    B[Protein Sequence] --> D\n",
        "    C[Cryo-EM Map] --> D\n",
        "    D --> E[Structure Prediction]\n",
        "    D --> F[Validation]\n",
        "    D --> G[Hydrodynamics]\n",
        "    E --> H[VR Visualization]\n",
        "    F --> I[Blockchain Audit]\n",
        "    F --> J[OneDep Deposition]"
      ],
      "metadata": {
        "id": "Ch4ya_XBWRMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wq9DCuDWARtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Execution Flow**:\n",
        "1. Processes experimental biophysics data through 1D-CNN\n",
        "2. Predicts protein structure from sequence via dense embeddings\n",
        "3. Fuses experimental, predictive, and validation data streams\n",
        "4. Generates:\n",
        "   - Molecular structure visualization\n",
        "   - Hydrodynamic property predictions\n",
        "   - Blockchain-validated audit trail\n",
        "   - Automated PDB deposition\n",
        "5. Outputs VR-ready collaborative environment\n",
        "\n",
        "**Technical Compression**:\n",
        "- Combines TensorFlow, Py3Dmol, NanomeVR, and Web3.py in unified graph\n",
        "- Uses Keras functional API for multimodal fusion\n",
        "- Lambda layers for blockchain/API operations\n",
        "- Symbolic representation of:\n",
        "  - AlphaFold-like prediction (Dense(2048))\n",
        "  - Cryo-EM integration (implicit in fusion)\n",
        "  - Validation compliance (Concatenate layer)\n",
        "  - VR/3D visualization (py3Dmol + Nanome)\n",
        "\n",
        "This representation abstracts the core collaboration between wet-lab experiments (biophysics), dry-lab predictions (AI), and immersive validation (VR) while maintaining rigorous compliance standards through blockchain and OneDep integration"
      ],
      "metadata": {
        "id": "ro7nPlFLW1qc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submission File"
      ],
      "metadata": {
        "id": "ivI2ZsT9WRj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# install from pypi\n",
        "uv pip install -U cell-eval\n",
        "\n",
        "# install from github directly\n",
        "uv pip install -U git+ssh://github.com/arcinstitute/cell-eval\n",
        "\n",
        "# install cli with uv tool\n",
        "uv tool install -U git+ssh://github.com/arcinstitute/cell-eval\n",
        "\n",
        "# Check installation\n",
        "cell-eval --help\n",
        "\n",
        "# Visualize the anndatasets\n",
        "1. predicted anndata (adata_pred).\n",
        "2. real anndata to compare against (adata_real).\n",
        "\n",
        "# cell-eval prep\n",
        "cell-eval prep \\\n",
        "    -i <your/path/to>.h5ad \\\n",
        "    -g <expected_genelist>\n",
        "\n",
        "# cell-eval run to run differential expression\n",
        "--profile flag)# select metrics\n",
        "# cell-eval run --help\n",
        "cell-eval run \\\n",
        "    -ap <your/path/to/pred>.h5ad \\\n",
        "    -ar <your/path/to/real>.h5ad \\\n",
        "    --num-threads 64 \\\n",
        "    --profile full\n",
        "\n",
        "# use MetricsEvaluator class.\n",
        "\n",
        "from cell_eval import MetricsEvaluator\n",
        "from cell_eval.data import build_random_anndata, downsample_cells\n",
        "\n",
        "adata_real = build_random_anndata()\n",
        "adata_pred = downsample_cells(adata_real, fraction=0.5)\n",
        "evaluator = MetricsEvaluator(\n",
        "    adata_pred=adata_pred,\n",
        "    adata_real=adata_real,\n",
        "    control_pert=\"control\",\n",
        "    pert_col=\"perturbation\",\n",
        "    num_threads=64,\n",
        ")\n",
        "(results, agg_results) = evaluator.compute()\n",
        "(results)\n",
        "(agg_results)\n",
        "# Normalize scores against a baseline\n",
        "cell-eval score\n",
        "agg_results.csv\n",
        "agg_results\n",
        "\n",
        "cell-eval score \\\n",
        "    --user-input <your/path/to/user>/agg_results.csv \\\n",
        "    --base-input <your/path/to/base>/agg_results.csv\n",
        "from cell_eval import score_agg_metrics\n",
        "\n",
        "user_input = \"./cell-eval-user/agg_results.csv\"\n",
        "base_input = \"./cell-eval-base/agg_results.csv\"\n",
        "output_path = \"./score.csv\"\n",
        "\n",
        "score_agg_metrics(\n",
        "    results_user=user_input,\n",
        "    results_base=base_input,\n",
        "    output=output_path,\n",
        ")\n",
        "\n",
        "cell_eval.metrics\n",
        "\n",
        "VCC Submission file path\n",
        "cell-eval installed and in your $PATH# use installation guide"
      ],
      "metadata": {
        "id": "juck1vTiWSBC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}